{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "DIAGNOSIS = \"acl\"\n",
        "PLANE = \"sagittal\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "KAGGLE =  os.getenv(\"KAGGLE_URL_BASE\") is not None\n",
        "COLAB = os.getenv(\"COLAB_GPU\") is not None\n",
        "TPU = os.getenv(\"XRT_TPU_CONFIG\") is not None\n",
        "LOCAL = not KAGGLE and not COLAB\n",
        "\n",
        "if not LOCAL:\n",
        "    !git clone https://github.com/nclibz/MRKnee/\n",
        "\n",
        "if COLAB:\n",
        "    os.chdir('/content/MRKnee/')\n",
        "    !git checkout v3\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    DATADIR = \"/content/drive/MyDrive/MRKnee/data\"\n",
        "    if TPU:\n",
        "        !pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n",
        "\n",
        "if KAGGLE:\n",
        "    os.chdir('/kaggle/working/MRKnee/')\n",
        "    !git checkout v3\n",
        "    dataset_name = os.listdir('/kaggle/input')[0]\n",
        "    \n",
        "    DATADIR = f\"/kaggle/input/{dataset_name}/MRNet\"\n",
        "    \n",
        "    if TPU:\n",
        "        !pip install torchtext==0.9\n",
        "        !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "        !python pytorch-xla-env-setup.py --version 1.8\n",
        "\n",
        "if not LOCAL:\n",
        "    !pip install --quiet \"pytorch-lightning>=1.4.9\" \"torchmetrics>=0.5\" \"timm\" \"neptune-client\" \"optuna\" \"PyMySql\"\n",
        "    !pip install albumentations --upgrade --quiet\n",
        "    BACKBONE = \"tf_efficientnetv2_s_in21k\"\n",
        "\n",
        "if LOCAL:\n",
        "    DATADIR = \"data\"\n",
        "    BACKBONE = 'tf_mobilenetv3_small_minimal_100'\n",
        "    %load_ext autoreload\n",
        "    %autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mS6KbHiLEwJi"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Global seed set to 123\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "123"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from src.study import Study\n",
        "from src.model import MRKnee\n",
        "from src.data import MRKneeDataModule\n",
        "from src.augmentations import Augmentations\n",
        "from src.callbacks import Callbacks\n",
        "from src.cfg import Cfg\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "pl.seed_everything(123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0odqVZ7KEwJj"
      },
      "outputs": [],
      "source": [
        "\n",
        "def objective(trial, diagnosis=DIAGNOSIS, plane=PLANE, backbone=BACKBONE, datadir=DATADIR):\n",
        "\n",
        "    model = MRKnee(\n",
        "        backbone=backbone,\n",
        "        drop_rate=trial.suggest_int(\"drop_rate\", 30, 90, step = 10) / 100,\n",
        "        learning_rate=trial.suggest_loguniform('lr', 1e-6, 1e-3),\n",
        "        adam_wd=trial.suggest_loguniform('adam_wd', 0.001, 0.3),\n",
        "        max_epochs=20,\n",
        "        precision=32,\n",
        "        log_auc=True,\n",
        "        log_ind_loss=False,\n",
        "    )\n",
        "\n",
        "    augs = Augmentations(\n",
        "        model,\n",
        "        max_res_train = 256,\n",
        "        shift_limit=trial.suggest_int(\"shift_limit\", 0, 25, step = 5) / 100,\n",
        "        scale_limit=trial.suggest_int(\"scale_limit\", 0, 25, step = 5) / 100,\n",
        "        rotate_limit=trial.suggest_int(\"rotate_limit\", 0, 25, step = 5) / 100,\n",
        "        ssr_p=trial.suggest_int(\"ShiftScaleRotate_p\", 20, 80, step = 10) / 100,\n",
        "        clahe_p=trial.suggest_int(\"clahe_p\", 20, 80, step = 10) / 100,\n",
        "        reverse_p=0.0,\n",
        "        indp_normalz=True,\n",
        "    )\n",
        "\n",
        "    dm = MRKneeDataModule(\n",
        "        datadir=datadir,\n",
        "        diagnosis=diagnosis,\n",
        "        plane=plane,\n",
        "        transforms=augs,\n",
        "        clean=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        trim_train=True,\n",
        "    )\n",
        "\n",
        "    configs = Cfg(model = model, dm = dm, augs = augs)\n",
        "    cfg = configs.get_cfg()\n",
        "    \n",
        "    callbacks = Callbacks(cfg, trial, neptune_name=\"mrkneev3\")\n",
        "    neptune_logger = callbacks.get_neptune_logger()\n",
        "    list_of_cbs = callbacks.get_callbacks()\n",
        "    fast_dev_run = False\n",
        "    \n",
        "    if LOCAL:\n",
        "        fast_dev_run = 50\n",
        "    \n",
        "    trainer = pl.Trainer(\n",
        "        gpus=1,\n",
        "        precision=cfg[\"precision\"],\n",
        "        max_epochs=cfg[\"max_epochs\"],\n",
        "        logger=neptune_logger,\n",
        "        log_every_n_steps=100,\n",
        "        num_sanity_val_steps=0,\n",
        "        callbacks=list_of_cbs,\n",
        "        progress_bar_refresh_rate=20,\n",
        "        deterministic=False,\n",
        "        fast_dev_run = False,\n",
        "    )\n",
        "\n",
        "    trainer.fit(model, dm)\n",
        "\n",
        "    ## UPLOAD BEST CHECKPOINTS TO LOG\n",
        "    # if not LOCAL:\n",
        "    #     callbacks.upload_best_checkpoints()\n",
        "\n",
        "    return callbacks.model_checkpoint.best_model_score.item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nicolai/miniconda3/envs/dl/lib/python3.9/site-packages/optuna/samplers/_tpe/sampler.py:263: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2021-11-21 10:45:19,646]\u001b[0m Using an existing study with name 'acl_sagittal_tf_mobilenetv3_small_minimal_100' instead of creating a new one.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "if DIAGNOSIS == \"meniscus\":\n",
        "    threshold = 1.2\n",
        "else:\n",
        "    threshold = 1\n",
        "\n",
        "study = Study(diagnosis = DIAGNOSIS,\n",
        "              plane = PLANE,\n",
        "              backbone=BACKBONE,\n",
        "              n_warmup_steps=5, \n",
        "              threshold=threshold) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JdYUoCTxEwJk"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nicolai/miniconda3/envs/dl/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://ui.neptune.ai/nclibz/mrkneev3/e/MRKNEEV-161\n",
            "Remember to stop your run once youâ€™ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nicolai/miniconda3/envs/dl/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:90: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=20)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
            "  rank_zero_deprecation(\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "/home/nicolai/miniconda3/envs/dl/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
            "  rank_zero_deprecation(\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name     | Type        | Params\n",
            "-----------------------------------------\n",
            "0 | backbone | MobileNetV3 | 1.0 M \n",
            "1 | clf      | Linear      | 1.0 K \n",
            "2 | val_auc  | AUROC       | 0     \n",
            "-----------------------------------------\n",
            "1.0 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.0 M     Total params\n",
            "4.082     Total estimated model params size (MB)\n",
            "/home/nicolai/miniconda3/envs/dl/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:110: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "/home/nicolai/miniconda3/envs/dl/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:110: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/1241 [00:00<?, ?it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nicolai/miniconda3/envs/dl/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:56: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  warning_cache.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1241/1241 [01:18<00:00, 15.82it/s, loss=1.23, v_num=-161, val_auc=0.500, val_loss=0.771]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 0, global step 1120: val_loss reached 0.77070 (best 0.77070), saving model to \"/home/nicolai/OneDrive/Forskning/Projekter/MRKnee/checkpoints/trial10/epoch=00-val_loss=0.77-val_auc=0.50.ckpt\" as top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1241/1241 [01:16<00:00, 16.29it/s, loss=0.902, v_num=-161, val_auc=0.590, val_loss=0.752, train_loss=1.180]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1, global step 2241: val_loss reached 0.75207 (best 0.75207), saving model to \"/home/nicolai/OneDrive/Forskning/Projekter/MRKnee/checkpoints/trial10/epoch=01-val_loss=0.75-val_auc=0.59.ckpt\" as top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1241/1241 [01:14<00:00, 16.76it/s, loss=0.674, v_num=-161, val_auc=0.702, val_loss=0.731, train_loss=1.020]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2, global step 3362: val_loss reached 0.73060 (best 0.73060), saving model to \"/home/nicolai/OneDrive/Forskning/Projekter/MRKnee/checkpoints/trial10/epoch=02-val_loss=0.73-val_auc=0.70.ckpt\" as top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1241/1241 [00:59<00:00, 20.86it/s, loss=0.98, v_num=-161, val_auc=0.738, val_loss=0.727, train_loss=0.889] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3, global step 4483: val_loss reached 0.72662 (best 0.72662), saving model to \"/home/nicolai/OneDrive/Forskning/Projekter/MRKnee/checkpoints/trial10/epoch=03-val_loss=0.73-val_auc=0.74.ckpt\" as top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1241/1241 [00:59<00:00, 20.85it/s, loss=0.54, v_num=-161, val_auc=0.794, val_loss=0.703, train_loss=0.801] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4, global step 5604: val_loss reached 0.70256 (best 0.70256), saving model to \"/home/nicolai/OneDrive/Forskning/Projekter/MRKnee/checkpoints/trial10/epoch=04-val_loss=0.70-val_auc=0.79.ckpt\" as top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1241/1241 [01:00<00:00, 20.52it/s, loss=0.557, v_num=-161, val_auc=0.797, val_loss=0.697, train_loss=0.703]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5, global step 6725: val_loss reached 0.69683 (best 0.69683), saving model to \"/home/nicolai/OneDrive/Forskning/Projekter/MRKnee/checkpoints/trial10/epoch=05-val_loss=0.70-val_auc=0.80.ckpt\" as top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1241/1241 [01:01<00:00, 20.02it/s, loss=0.393, v_num=-161, val_auc=0.815, val_loss=0.695, train_loss=0.623]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6, global step 7846: val_loss reached 0.69452 (best 0.69452), saving model to \"/home/nicolai/OneDrive/Forskning/Projekter/MRKnee/checkpoints/trial10/epoch=06-val_loss=0.69-val_auc=0.81.ckpt\" as top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1241/1241 [01:00<00:00, 20.59it/s, loss=0.425, v_num=-161, val_auc=0.831, val_loss=0.674, train_loss=0.540]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7, global step 8967: val_loss reached 0.67398 (best 0.67398), saving model to \"/home/nicolai/OneDrive/Forskning/Projekter/MRKnee/checkpoints/trial10/epoch=07-val_loss=0.67-val_auc=0.83.ckpt\" as top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1241/1241 [00:59<00:00, 20.84it/s, loss=0.287, v_num=-161, val_auc=0.839, val_loss=0.666, train_loss=0.486]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8, global step 10088: val_loss reached 0.66583 (best 0.66583), saving model to \"/home/nicolai/OneDrive/Forskning/Projekter/MRKnee/checkpoints/trial10/epoch=08-val_loss=0.67-val_auc=0.84.ckpt\" as top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1241/1241 [00:59<00:00, 20.99it/s, loss=0.511, v_num=-161, val_auc=0.847, val_loss=0.627, train_loss=0.408]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9, global step 11209: val_loss reached 0.62747 (best 0.62747), saving model to \"/home/nicolai/OneDrive/Forskning/Projekter/MRKnee/checkpoints/trial10/epoch=09-val_loss=0.63-val_auc=0.85.ckpt\" as top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1241/1241 [00:59<00:00, 20.89it/s, loss=0.424, v_num=-161, val_auc=0.854, val_loss=0.609, train_loss=0.347]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10, global step 12330: val_loss reached 0.60927 (best 0.60927), saving model to \"/home/nicolai/OneDrive/Forskning/Projekter/MRKnee/checkpoints/trial10/epoch=10-val_loss=0.61-val_auc=0.85.ckpt\" as top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1241/1241 [00:59<00:00, 20.82it/s, loss=0.162, v_num=-161, val_auc=0.859, val_loss=0.669, train_loss=0.317]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11, global step 13451: val_loss was not in top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1241/1241 [00:59<00:00, 20.81it/s, loss=0.156, v_num=-161, val_auc=0.816, val_loss=0.659, train_loss=0.263]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12, global step 14572: val_loss was not in top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1241/1241 [00:59<00:00, 20.86it/s, loss=0.118, v_num=-161, val_auc=0.792, val_loss=0.780, train_loss=0.220]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13, global step 15693: val_loss was not in top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14:  27%|â–ˆâ–ˆâ–‹       | 340/1241 [00:16<00:44, 20.04it/s, loss=0.0722, v_num=-161, val_auc=0.792, val_loss=0.780, train_loss=0.172]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nicolai/miniconda3/envs/dl/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:685: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        }
      ],
      "source": [
        "study.optimize(objective, n_trials=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "colab.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "abca6c4c30ca8b1572eaf6dbdb066fe101b3df9342c8f2ea2bdb847c9dcb6eec"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('dl': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
