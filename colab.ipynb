{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaEqMmnJEwJf",
        "outputId": "0987e5d2-8dfe-4979-b28e-5488e7225296",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jan 24 15:46:52 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P8    34W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "source": [
        "# SETUP"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi08op7TEwJh"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtEbNHIEEwJh"
      },
      "source": [
        "# setup wd and datadir\n",
        "!git clone https://github.com/nclibz/MRKnee/\n",
        "import os\n",
        "os.chdir('/content/MRKnee/')\n",
        "!git checkout lstm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCnk5_E6EwJh"
      },
      "source": [
        "!pip install pytorch-lightning\n",
        "!pip install timm\n",
        "!pip install neptune-client\n",
        "!pip install albumentations -U\n",
        "!pip install optuna\n",
        "!pip install PyMySql"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# MODEL"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS6KbHiLEwJi"
      },
      "source": [
        "from optuna.integration import PyTorchLightningPruningCallback\n",
        "import optuna\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import loggers as pl_loggers\n",
        "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
        "from model import MRKnee\n",
        "from data import MRKneeDataModule\n",
        "import albumentations as A\n",
        "from pytorch_lightning import Callback\n",
        "pl.seed_everything(123)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 123\n",
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9OxOfAiEwJi"
      },
      "source": [
        "class MetricsCallback(Callback):\n",
        "    \"\"\"PyTorch Lightning metric callback.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.metrics = []\n",
        "\n",
        "    def on_validation_end(self, trainer, pl_module):\n",
        "        self.metrics.append(trainer.callback_metrics)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0odqVZ7KEwJj"
      },
      "source": [
        "\n",
        "def objective(trial):\n",
        "\n",
        "    BACKBONE = 'efficientnet_b0'\n",
        "    if 'b0' in BACKBONE: \n",
        "        IMG_SZ = 224\n",
        "    elif 'b1' in BACKBONE:\n",
        "        IMG_SZ = 240\n",
        "\n",
        "    cfg = {\n",
        "        # DATA\n",
        "        'datadir': '/content/drive/MyDrive/MRKnee/data',\n",
        "        'diagnosis': 'meniscus',\n",
        "        'planes': ['axial'],  # , 'sagittal', 'coronal', 'axial',\n",
        "        'n_chans': 1,\n",
        "        'num_workers': 4,\n",
        "        'pin_memory': True,\n",
        "        'upsample': False,\n",
        "        'w_loss': True,\n",
        "        'same_range': True,\n",
        "        'indp_normalz': True,\n",
        "        'transf': {\n",
        "            'train': [A.ShiftScaleRotate(always_apply=False, p=1.0,\n",
        "                        shift_limit=trial.suggest_float('shift', 0, 0.15),\n",
        "                        scale_limit=trial.suggest_float('scale', 0, 0.10),\n",
        "                        rotate_limit=trial.suggest_int('rotate', 0, 35)\n",
        "                        ),\n",
        "                      A.HorizontalFlip(p=trial.suggest_float('flip_p', 0, 0.5)),\n",
        "                      A.CenterCrop(IMG_SZ, IMG_SZ)],\n",
        "            'valid': [A.CenterCrop(IMG_SZ, IMG_SZ)]\n",
        "        },\n",
        "        # MODEL\n",
        "        'backbone': BACKBONE,\n",
        "        'pretrained': True,\n",
        "        'learning_rate': trial.suggest_loguniform('lr', 1e-6, 1e-2),\n",
        "        'drop_rate': trial.suggest_float('dropout', 0., 0.6),\n",
        "        'final_drop': trial.suggest_float('f_drp',0,0.6),\n",
        "        'freeze_from': -1,\n",
        "        'unfreeze_epoch': 0,\n",
        "        'log_auc': True,\n",
        "        'log_ind_loss': False,\n",
        "        'final_pool': trial.suggest_categorical('final_pool', ['max', 'last_t_step'])\n",
        "        'lstm': True, \n",
        "        'lstm_layers': 1,\n",
        "        'lstm_h_size': trial.suggest_int('h_size', 1280, 2560, step = 8), \n",
        "\n",
        "        # Trainer\n",
        "        'precision': 32,\n",
        "        'max_epochs': 20,\n",
        "    }\n",
        "\n",
        "\n",
        "    # LOGGER\n",
        "    neptune_logger = pl_loggers.NeptuneLogger(\n",
        "        api_key=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5haSIsImFwaV91cmwiOiJodHRwczovL3VpLm5lcHR1bmUuYWkiLCJhcGlfa2V5IjoiNDI5ODUwMzQtOTM0Mi00YTY2LWExYWQtMDNlZDZhY2NlYjUzIn0=\",\n",
        "        params=cfg,\n",
        "        project_name='nclibz/optuna-test',\n",
        "        tags=[cfg['diagnosis']] + cfg['planes']\n",
        "    )\n",
        "\n",
        "    # Callbacks\n",
        "    #model_checkpoint = ModelCheckpoint(dirpath=f'checkpoints/trial{trial.number}/',\n",
        "    #                                   filename='{epoch:02d}-{val_loss:.2f}-{val_auc:.2f}',\n",
        "    #                                   verbose=True,\n",
        "    #                                   save_top_k=2,\n",
        "    #                                   monitor='val_loss',\n",
        "    #                                   mode='min',\n",
        "    #                                   period=1)\n",
        "\n",
        "    lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval=\"epoch\")\n",
        "\n",
        "    metrics_callback = MetricsCallback()\n",
        "\n",
        "    prune_callback = PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")\n",
        "\n",
        "    # DM AND MODEL\n",
        "    dm = MRKneeDataModule(**cfg)\n",
        "    model = MRKnee(**cfg)\n",
        "    trainer = pl.Trainer(gpus=1,\n",
        "                         precision=cfg['precision'],\n",
        "                         max_epochs=cfg['max_epochs'],\n",
        "                         logger=neptune_logger,\n",
        "                         log_every_n_steps=100,\n",
        "                         num_sanity_val_steps=0,\n",
        "                         callbacks=[lr_monitor,\n",
        "                                 #   model_checkpoint,\n",
        "                                    metrics_callback,\n",
        "                                    prune_callback],\n",
        "                         progress_bar_refresh_rate=20,\n",
        "                         deterministic=True)\n",
        "\n",
        "    trainer.fit(model, dm)\n",
        "\n",
        "    return  metrics_callback.metrics[-1][\"val_loss\"].item()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdYUoCTxEwJk"
      },
      "source": [
        "pruner = optuna.pruners.HyperbandPruner(min_resource=5)\n",
        "sampler = optuna.samplers.TPESampler(multivariate=True)\n",
        "study = optuna.create_study(storage = \"mysql+pymysql://admin:Testuser1234@database-1.c17p2riuxscm.us-east-2.rds.amazonaws.com/optuna\", \n",
        "                            study_name = \"test15\", load_if_exists=True, sampler = sampler, pruner = pruner, direction= \"minimize\")\n",
        "\n",
        "study.enqueue_trial({\n",
        "    'dropout': 0.392066,\n",
        "    'flip_p': 0.152153,\n",
        "    'lr': 5.37215e-06,\n",
        "    'rotate': 3,\n",
        "    'scale': 0.0489214,\n",
        "    'shift': 0.0806249,\n",
        "    'f_drp': 0.35,\n",
        "    'h_size': 1280\n",
        "    })\n",
        "\n",
        "\n",
        "study.optimize(objective, n_trials=40, timeout=8*60*60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQea-_xFEwJk"
      },
      "source": [
        "## UPLOAD BEST CHECKPOINTS TO LOG\n",
        "#neptune_logger.experiment.set_property('best_val_loss', model_checkpoint.best_model_score.tolist())\n",
        "#for k in model_checkpoint.best_k_models.keys():\n",
        "#    model_name = 'checkpoints/' + k.split('/')[-1]\n",
        "#    neptune_logger.experiment.log_artifact(k, model_name)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zs71tuRcEwJl"
      },
      "source": [
        "### UPLOAD  SAMPLE LOSSES  - tager dog den sidste og ik ved bedste val. Skal implementere inde i modellen\n",
        "#from neptunecontrib.api import log_pickle\n",
        "#log_pickle('v_sample_loss.pkl', model.v_sample_loss, neptune_logger)\n",
        "#log_pickle('t_sample_loss.pkl', model.t_sample_loss, neptune_logger)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}