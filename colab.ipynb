{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "DIAGNOSIS = \"acl\"\n",
        "PLANE = \"sagittal\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "KAGGLE =  os.getenv(\"KAGGLE_URL_BASE\") is not None\n",
        "COLAB = os.getenv(\"COLAB_GPU\") is not None\n",
        "TPU = os.getenv(\"XRT_TPU_CONFIG\") is not None\n",
        "LOCAL = not KAGGLE and not COLAB\n",
        "\n",
        "if not LOCAL:\n",
        "    !git clone https://github.com/nclibz/MRKnee/\n",
        "\n",
        "if COLAB:\n",
        "    os.chdir('/content/MRKnee/')\n",
        "    !git checkout v3\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    DATADIR = \"/content/drive/MyDrive/MRKnee/data\"\n",
        "    if TPU:\n",
        "        !pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n",
        "\n",
        "if KAGGLE:\n",
        "    os.chdir('/kaggle/working/MRKnee/')\n",
        "    !git checkout v3\n",
        "    dataset_name = os.listdir('/kaggle/input')[0]\n",
        "    \n",
        "    DATADIR = f\"/kaggle/input/{dataset_name}/MRNet\"\n",
        "    \n",
        "    if TPU:\n",
        "        !pip install torchtext==0.9\n",
        "        !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "        !python pytorch-xla-env-setup.py --version 1.8\n",
        "\n",
        "if not LOCAL:\n",
        "    !pip install --quiet \"pytorch-lightning>=1.4.9\" \"torchmetrics>=0.5\" \"timm\" \"neptune-client\" \"optuna\" \"PyMySql\"\n",
        "    !pip install albumentations --upgrade --quiet\n",
        "    BACKBONE = \"tf_efficientnetv2_s_in21k\"\n",
        "\n",
        "if LOCAL:\n",
        "    DATADIR = \"data\"\n",
        "    BACKBONE = 'tf_mobilenetv3_small_minimal_100'\n",
        "    %load_ext autoreload\n",
        "    %autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mS6KbHiLEwJi"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Global seed set to 123\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "123"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from src.study import Study\n",
        "from src.model import MRKnee\n",
        "from src.data import MRKneeDataModule\n",
        "from src.augmentations import Augmentations\n",
        "from src.callbacks import Callbacks\n",
        "from src.cfg import Cfg\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "pl.seed_everything(123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0odqVZ7KEwJj"
      },
      "outputs": [],
      "source": [
        "\n",
        "def objective(trial, diagnosis=DIAGNOSIS, plane=PLANE, backbone=BACKBONE, datadir=DATADIR):\n",
        "\n",
        "    model = MRKnee(\n",
        "        backbone=backbone,\n",
        "        drop_rate=trial.suggest_int(\"drop_rate\", 30, 95, step = 5) / 100,\n",
        "        learning_rate=trial.suggest_loguniform('lr', 1e-6, 1e-3),\n",
        "        adam_wd=trial.suggest_loguniform('adam_wd', 0.001, 0.3),\n",
        "        max_epochs=20,\n",
        "        precision=32,\n",
        "        log_auc=True,\n",
        "        log_ind_loss=False,\n",
        "    )\n",
        "\n",
        "    clahe = trial.suggest_categorical(\"clahe\", [True, False])\n",
        "    clahe_valid = trial.suggest_categorical(\"clahe_valid\", [True, False]) if clahe else False\n",
        "\n",
        "    augs = Augmentations(\n",
        "        model,\n",
        "        max_res_train = 256,\n",
        "        shift_limit=trial.suggest_int(\"shift_limit\", 0, 15) / 100,\n",
        "        scale_limit=trial.suggest_int(\"scale_limit\", 0, 15) / 100,\n",
        "        rotate_limit=trial.suggest_int(\"rotate_limit\", 0, 15) / 100,\n",
        "        ssr_p=trial.suggest_int(\"ShiftScaleRotate_p\", 20, 80, step = 5) / 100,\n",
        "        clahe=clahe,\n",
        "        clahe_valid = clahe,\n",
        "        reverse_p=0.0,\n",
        "        indp_normalz=True,\n",
        "    )\n",
        "\n",
        "    dm = MRKneeDataModule(\n",
        "        datadir=datadir,\n",
        "        diagnosis=diagnosis,\n",
        "        plane=plane,\n",
        "        transforms=augs,\n",
        "        clean=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        trim_train=True,\n",
        "    )\n",
        "\n",
        "    configs = Cfg(model = model, dm = dm, augs = augs)\n",
        "    cfg = configs.get_cfg()\n",
        "    \n",
        "    callbacks = Callbacks(cfg, trial, neptune_name=\"mrkneev3\")\n",
        "    neptune_logger = callbacks.get_neptune_logger()\n",
        "    list_of_cbs = callbacks.get_callbacks()\n",
        "    fast_dev_run = False\n",
        "    \n",
        "    if LOCAL:\n",
        "        fast_dev_run = 50\n",
        "    \n",
        "    trainer = pl.Trainer(\n",
        "        gpus=1,\n",
        "        precision=cfg[\"precision\"],\n",
        "        max_epochs=cfg[\"max_epochs\"],\n",
        "        logger=neptune_logger,\n",
        "        log_every_n_steps=100,\n",
        "        num_sanity_val_steps=0,\n",
        "        callbacks=list_of_cbs,\n",
        "        progress_bar_refresh_rate=20,\n",
        "        deterministic=False,\n",
        "        fast_dev_run = False,\n",
        "    )\n",
        "\n",
        "    trainer.fit(model, dm)\n",
        "\n",
        "    ## UPLOAD BEST CHECKPOINTS TO LOG\n",
        "    # if not LOCAL:\n",
        "    #     callbacks.upload_best_checkpoints()\n",
        "\n",
        "    return callbacks.model_checkpoint.best_model_score.item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nicolai/miniconda3/envs/dl/lib/python3.9/site-packages/optuna/samplers/_tpe/sampler.py:263: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2021-11-21 10:22:45,754]\u001b[0m Using an existing study with name 'acl_sagittal_tf_mobilenetv3_small_minimal_100' instead of creating a new one.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "if DIAGNOSIS == \"meniscus\":\n",
        "    threshold = 1.2\n",
        "else:\n",
        "    threshold = 1\n",
        "\n",
        "study = Study(diagnosis = DIAGNOSIS,\n",
        "              plane = PLANE,\n",
        "              backbone=BACKBONE,\n",
        "              n_warmup_steps=5, \n",
        "              threshold=threshold) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JdYUoCTxEwJk"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nicolai/miniconda3/envs/dl/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://ui.neptune.ai/nclibz/mrkneev3/e/MRKNEEV-160\n",
            "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nicolai/miniconda3/envs/dl/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:90: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=20)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
            "  rank_zero_deprecation(\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "/home/nicolai/miniconda3/envs/dl/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
            "  rank_zero_deprecation(\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name     | Type        | Params\n",
            "-----------------------------------------\n",
            "0 | backbone | MobileNetV3 | 1.0 M \n",
            "1 | clf      | Linear      | 1.0 K \n",
            "2 | val_auc  | AUROC       | 0     \n",
            "-----------------------------------------\n",
            "1.0 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.0 M     Total params\n",
            "4.082     Total estimated model params size (MB)\n",
            "/home/nicolai/miniconda3/envs/dl/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:110: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "/home/nicolai/miniconda3/envs/dl/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:110: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/1241 [00:00<?, ?it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nicolai/miniconda3/envs/dl/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:56: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  warning_cache.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: 100%|██████████| 1241/1241 [01:00<00:00, 20.55it/s, loss=1.83, v_num=-160, val_auc=0.522, val_loss=0.778]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 0, global step 1120: val_loss reached 0.77782 (best 0.77782), saving model to \"/home/nicolai/OneDrive/Forskning/Projekter/MRKnee/checkpoints/trial8/epoch=00-val_loss=0.78-val_auc=0.52.ckpt\" as top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 1241/1241 [00:59<00:00, 20.93it/s, loss=0.851, v_num=-160, val_auc=0.618, val_loss=0.764, train_loss=1.480]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1, global step 2241: val_loss reached 0.76379 (best 0.76379), saving model to \"/home/nicolai/OneDrive/Forskning/Projekter/MRKnee/checkpoints/trial8/epoch=01-val_loss=0.76-val_auc=0.62.ckpt\" as top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 1241/1241 [00:59<00:00, 20.91it/s, loss=0.869, v_num=-160, val_auc=0.645, val_loss=0.752, train_loss=1.140]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2, global step 3362: val_loss reached 0.75246 (best 0.75246), saving model to \"/home/nicolai/OneDrive/Forskning/Projekter/MRKnee/checkpoints/trial8/epoch=02-val_loss=0.75-val_auc=0.65.ckpt\" as top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 1241/1241 [00:58<00:00, 21.06it/s, loss=1.16, v_num=-160, val_auc=0.549, val_loss=0.764, train_loss=0.987]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3, global step 4483: val_loss was not in top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 1241/1241 [00:57<00:00, 21.65it/s, loss=0.574, v_num=-160, val_auc=0.580, val_loss=0.782, train_loss=0.914]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4, global step 5604: val_loss was not in top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 1241/1241 [00:57<00:00, 21.60it/s, loss=0.535, v_num=-160, val_auc=0.644, val_loss=0.759, train_loss=0.830]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5, global step 6725: val_loss reached 0.75877 (best 0.75246), saving model to \"/home/nicolai/OneDrive/Forskning/Projekter/MRKnee/checkpoints/trial8/epoch=05-val_loss=0.76-val_auc=0.64.ckpt\" as top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6:   0%|          | 0/1241 [00:00<?, ?it/s, loss=0.535, v_num=-160, val_auc=0.644, val_loss=0.759, train_loss=0.830]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nicolai/miniconda3/envs/dl/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:685: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
            "\u001b[32m[I 2021-11-21 10:29:11,832]\u001b[0m Trial 8 finished with value: 0.7524612545967102 and parameters: {'drop_rate': 85, 'lr': 6.927471199789772e-05, 'adam_wd': 0.2964080283925666, 'shift_limit': 14, 'scale_limit': 10, 'rotate_limit': 13, 'clahe': False}. Best is trial 8 with value: 0.752461.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6:   0%|          | 0/1241 [00:16<?, ?it/s, loss=0.535, v_num=-160, val_auc=0.644, val_loss=0.759, train_loss=0.830]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nicolai/miniconda3/envs/dl/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "study.optimize(objective, n_trials=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "colab.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "abca6c4c30ca8b1572eaf6dbdb066fe101b3df9342c8f2ea2bdb847c9dcb6eec"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('dl': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
