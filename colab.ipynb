{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/nclibz/MRKnee/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-lightning\n",
    "!pip install timm\n",
    "!pip install neptune-client\n",
    "!pip install albumentations -U\n",
    "!pip install neptune-contrib\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup wd and datadir\n",
    "import os\n",
    "os.chdir('/content/MRKnee/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git pull https://github.com/nclibz/MRKnee/\n",
    "!git checkout optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git pull origin optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "import optuna\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from model import MRKnee\n",
    "from data import MRKneeDataModule\n",
    "import albumentations as A\n",
    "from pytorch_lightning import Callback\n",
    "from utils import print_top_losses\n",
    "\n",
    "\n",
    "pl.seed_everything(123)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCallback(Callback):\n",
    "    \"\"\"PyTorch Lightning metric callback.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.metrics = []\n",
    "\n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        self.metrics.append(trainer.callback_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective(trial):\n",
    "\n",
    "    IMG_SZ = 224  # b0 = 224, b1 = 240,\n",
    "\n",
    "    cfg = {\n",
    "        # DATA\n",
    "        'datadir': '/content/drive/MyDrive/MRKnee/data',\n",
    "        'diagnosis': 'meniscus',\n",
    "        'planes': ['axial'],  # , 'sagittal', 'coronal', 'axial',\n",
    "        'n_chans': 1,\n",
    "        'num_workers': 4,\n",
    "        'pin_memory': True,\n",
    "        'upsample': False,\n",
    "        'w_loss': True,\n",
    "        'indp_normalz': False,\n",
    "        'transf': {\n",
    "            'train': [A.Rotate(limit=25, p=1),\n",
    "                      A.HorizontalFlip(p=0.5),\n",
    "                      A.RandomCrop(IMG_SZ, IMG_SZ)],\n",
    "            'valid': [A.CenterCrop(IMG_SZ, IMG_SZ)]\n",
    "        },\n",
    "        # MODEL\n",
    "        'backbone': 'efficientnet_b0',\n",
    "        'pretrained': True,\n",
    "        'learning_rate': trial.suggest_loguniform('lr', 1e-6, 1e-2),\n",
    "        'drop_rate': trial.suggest_float('dropout', 0., 0.8),\n",
    "        'freeze_from': -1,\n",
    "        'unfreeze_epoch': 0,\n",
    "        'log_auc': True,\n",
    "        'log_ind_loss': False,\n",
    "        'final_pool': 'max',\n",
    "        # Trainer\n",
    "        'precision': 16,\n",
    "        'max_epochs': 5,\n",
    "    }\n",
    "\n",
    "    # LOGGER\n",
    "    neptune_logger = pl_loggers.NeptuneLogger(\n",
    "        api_key=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5haSIsImFwaV91cmwiOiJodHRwczovL3VpLm5lcHR1bmUuYWkiLCJhcGlfa2V5IjoiNDI5ODUwMzQtOTM0Mi00YTY2LWExYWQtMDNlZDZhY2NlYjUzIn0=\",\n",
    "        params=cfg,\n",
    "        project_name='nclibz/optuna-test',\n",
    "        tags=[cfg['diagnosis']] + cfg['planes']\n",
    "    )\n",
    "\n",
    "    # Callbacks\n",
    "    model_checkpoint = ModelCheckpoint(dirpath=f'checkpoints/trial{trial.number}/',\n",
    "                                       filename='{epoch:02d}-{val_loss:.2f}-{val_auc:.2f}',\n",
    "                                       verbose=True,\n",
    "                                       save_top_k=2,\n",
    "                                       monitor='val_loss',\n",
    "                                       mode='min',\n",
    "                                       period=1)\n",
    "\n",
    "    lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval=\"epoch\")\n",
    "\n",
    "    metrics_callback = MetricsCallback()\n",
    "\n",
    "    prune_callback = PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")\n",
    "\n",
    "    # DM AND MODEL\n",
    "    dm = MRKneeDataModule(**cfg)\n",
    "    model = MRKnee(**cfg)\n",
    "    trainer = pl.Trainer(gpus=1,\n",
    "                         precision=cfg['precision'],\n",
    "                         max_epochs=cfg['max_epochs'],\n",
    "                         logger=neptune_logger,\n",
    "                         log_every_n_steps=100,\n",
    "                         num_sanity_val_steps=0,\n",
    "                         callbacks=[lr_monitor,\n",
    "                                    model_checkpoint,\n",
    "                                    metrics_callback,\n",
    "                                    prune_callback],\n",
    "                         progress_bar_refresh_rate=20,\n",
    "                         limit_train_batches=10,  # HUSK AT SLETTE\n",
    "                         deterministic=True)\n",
    "\n",
    "    trainer.fit(model, dm)\n",
    "\n",
    "    return metrics_callback.metrics[-1][\"val_loss\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner = optuna.pruners.HyperbandPruner(min_resource=3)\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "# skal vel ogs√• bruge en TPE sampler?\n",
    "#study = optuna.create_study(direction=\"minimize\", pruner=pruner, sampler = sampler)\n",
    "optuna.create_study(storage = \"mysql+pymysql://admin:Testuser1234@database-1.c17p2riuxscm.us-east-2.rds.amazonaws.com/optuna\", study_name = \"test2\", load_if_exists=True, sampler = sampler, pruner = pruner)\n",
    "\n",
    "study.optimize(objective, n_trials=4, timeout=None)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UPLOAD BEST CHECKPOINTS TO LOG\n",
    "neptune_logger.experiment.set_property('best_val_loss', model_checkpoint.best_model_score.tolist())\n",
    "for k in model_checkpoint.best_k_models.keys():\n",
    "    model_name = 'checkpoints/' + k.split('/')[-1]\n",
    "    neptune_logger.experiment.log_artifact(k, model_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UPLOAD  SAMPLE LOSSES  - tager dog den sidste og ik ved bedste val. Skal implementere inde i modellen\n",
    "from neptunecontrib.api import log_pickle\n",
    "log_pickle('v_sample_loss.pkl', model.v_sample_loss, neptune_logger)\n",
    "log_pickle('t_sample_loss.pkl', model.t_sample_loss, neptune_logger)"
   ]
  }
 ]
}