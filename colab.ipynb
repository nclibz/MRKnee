{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "DIAGNOSIS = \"meniscus\"\n",
        "PLANE = \"sagittal\"\n",
        "N_FOLDS = 5\n",
        "N_EPOCHS = 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "KAGGLE =  os.getenv(\"KAGGLE_URL_BASE\") is not None\n",
        "COLAB = os.getenv(\"COLAB_GPU\") is not None\n",
        "TPU = os.getenv(\"XRT_TPU_CONFIG\") is not None\n",
        "LOCAL = not KAGGLE and not COLAB\n",
        "\n",
        "if not LOCAL:\n",
        "    !git clone https://github.com/nclibz/MRKnee/\n",
        "\n",
        "if COLAB:\n",
        "    os.chdir('/content/MRKnee/')\n",
        "    !git checkout v3\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    DATADIR = \"/content/drive/MyDrive/MRKnee/data\"\n",
        "    if TPU:\n",
        "        !pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n",
        "\n",
        "if KAGGLE:\n",
        "    os.chdir('/kaggle/working/MRKnee/')\n",
        "    !git checkout v3\n",
        "    dataset_name = os.listdir('/kaggle/input')[0]\n",
        "    DATADIR = f\"/kaggle/input/{dataset_name}/\"\n",
        "    MODELDIR = DATADIR\n",
        "    \n",
        "    # INSTALL pyodbc driver\n",
        "    !sudo curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add -\n",
        "    !sudo curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list > /etc/apt/sources.list.d/mssql-release.list\n",
        "    !sudo apt-get update\n",
        "    !sudo ACCEPT_EULA=Y apt-get install -y msodbcsql18\n",
        "    \n",
        "    if TPU:\n",
        "        !pip install torchtext==0.9\n",
        "        !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "        !python pytorch-xla-env-setup.py --version 1.8\n",
        "\n",
        "if not LOCAL:\n",
        "    !pip install -U torchmetrics timm optuna albumentations scikit-image\n",
        "    %conda install -y pyodbc\n",
        "    BACKBONE = \"tf_efficientnetv2_s_in21k\"\n",
        "\n",
        "if LOCAL:\n",
        "    DATADIR = \"data\"\n",
        "    MODELDIR = \"src/\"\n",
        "    BACKBONE = 'tf_mobilenetv3_small_minimal_100'\n",
        "    %load_ext autoreload\n",
        "    %autoreload 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna\n",
        "import torch\n",
        "from optuna.pruners import ThresholdPruner\n",
        "from optuna.samplers import TPESampler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from tqdm import tqdm\n",
        "\n",
        "from src.augmentations import Augmentations\n",
        "from src.data import MRNet\n",
        "from src.metrics import AUC, Loss, MetricLogger\n",
        "from src.model import VanillaMRKnee\n",
        "from src.rdb import get_rdb_string\n",
        "from src.trainer import Trainer\n",
        "from src.utils import seed_everything\n",
        "\n",
        "seed_everything(123)\n",
        "rdb_string = get_rdb_string()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0odqVZ7KEwJj"
      },
      "outputs": [],
      "source": [
        "\n",
        "def objective(trial):\n",
        "    augs = Augmentations(\n",
        "        train_imgsize=(256, 256),\n",
        "        test_imgsize=(256, 256),\n",
        "        shift_limit=trial.suggest_int(\"shift_limit\", 0, 35, step = 5) / 100,\n",
        "        scale_limit=trial.suggest_int(\"scale_limit\", 0, 20, step = 5) / 100,\n",
        "        rotate_limit=trial.suggest_int(\"rotate_limit\", 0, 15, step = 5) / 100,\n",
        "        ssr_p=trial.suggest_int(\"ShiftScaleRotate_p\", 50, 80, step = 10) / 100,\n",
        "        clahe_p=trial.suggest_int(\"clahe_p\", 20, 70, step = 10) / 100,\n",
        "        reverse_p=0.0,\n",
        "        indp_normalz=True,\n",
        "        trim_p=0.1,\n",
        "    )\n",
        "\n",
        "    ds = MRNet(\n",
        "        stage=\"train\",\n",
        "        diagnosis=DIAGNOSIS,\n",
        "        plane=PLANE,\n",
        "        clean=True,\n",
        "        transforms=augs,\n",
        "        datadir = DATADIR + \"MRNet\"\n",
        "    )\n",
        "    # TODO: For OAI implement grouped strat kfold\n",
        "    splits = list(StratifiedKFold(N_FOLDS, shuffle=True).split(ds.ids, ds.lbls))\n",
        "\n",
        "    ## Start cv loop\n",
        "    fold_losses = []\n",
        "    for train_idxs, val_idxs in splits:\n",
        "        train_fold = Subset(ds, train_idxs)\n",
        "        train_dl = DataLoader(train_fold)\n",
        "        val_fold = Subset(ds, val_idxs)\n",
        "        val_dl = DataLoader(val_fold)\n",
        "\n",
        "        model = VanillaMRKnee(\n",
        "            BACKBONE,\n",
        "            drop_rate=trial.suggest_int(\"drop_rate\", 50, 90, step=10) / 100)\n",
        "        optimizer = torch.optim.AdamW(\n",
        "            model.parameters(),\n",
        "            lr=trial.suggest_loguniform('lr', 1e-4, 1e-2),\n",
        "            weight_decay=trial.suggest_loguniform('adam_wd', 0.01, 0.1),\n",
        "        )\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                               \"min\",\n",
        "                                                               patience=4)\n",
        "\n",
        "        metriclogger = MetricLogger(\n",
        "            train_metrics={\n",
        "                \"train_loss\": Loss(),\n",
        "                \"train_auc\": AUC(),\n",
        "            },\n",
        "            val_metrics={\n",
        "                \"val_loss\": Loss(),\n",
        "                \"val_auc\": AUC()\n",
        "            },\n",
        "        )\n",
        "\n",
        "        trainer = Trainer(model, optimizer, scheduler, metriclogger)\n",
        "\n",
        "        for epoch in tqdm(range(N_EPOCHS), desc='Epochs', disable=True):\n",
        "            trainer.train(train_dl)\n",
        "            trainer.test(val_dl)\n",
        "            # TODO: Den reporter vals til samme epoch step for alle folds -> så pruner virker kun for den første\n",
        "            #trial.report(metriclogger.val_loss.epoch_values[-1], epoch)\n",
        "\n",
        "            #if trial.should_prune():\n",
        "                #raise optuna.TrialPruned()\n",
        "\n",
        "        min_loss = torch.min(torch.Tensor(metriclogger.val_loss.epoch_values))\n",
        "        fold_losses.append(min_loss.to(\"cpu\"))\n",
        "\n",
        "    avg_cv_loss = torch.mean(torch.Tensor(fold_losses)).item()\n",
        "\n",
        "    return avg_cv_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if DIAGNOSIS == \"meniscus\":\n",
        "    THRESHOLD = 1.4\n",
        "else:\n",
        "    THRESHOLD = 1.0\n",
        "\n",
        "\n",
        "storage = optuna.storages.RDBStorage(\n",
        "            url=rdb_string,\n",
        "            heartbeat_interval=360,\n",
        "        )\n",
        "sampler = TPESampler(multivariate=True)\n",
        "\n",
        "study = optuna.create_study(\n",
        "    storage = storage,\n",
        "    study_name=f\"{DIAGNOSIS}_{PLANE}_{BACKBONE}\",\n",
        "    sampler = sampler,\n",
        "    pruner=ThresholdPruner(upper=THRESHOLD, n_warmup_steps=5, interval_steps=1),\n",
        "    load_if_exists=True,\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## best params\n",
        "men_sag = {\n",
        "    \"shift_limit\": 25, \n",
        "    \"rotate_limit\": 10,\n",
        "    \"scale_limit\": 10, \n",
        "    \"ssr_p\": 80,\n",
        "    \"adam_wd\": 0.0539477, \n",
        "    \"lr\": 0.000220,\n",
        "    \"drop_rate\": 90,\n",
        "    \"clahe_p\": 20\n",
        "    }\n",
        "\n",
        "study.enqueue_trial(men_sag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "study.optimize(objective, n_trials=1) # 1 trial = 8 hours. Kaggle limit = 9hrs"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "colab.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "abca6c4c30ca8b1572eaf6dbdb066fe101b3df9342c8f2ea2bdb847c9dcb6eec"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('dl': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
