{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "PLANE = \"sagittal\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "KAGGLE =  os.getenv(\"KAGGLE_URL_BASE\") is not None\n",
        "COLAB = os.getenv(\"COLAB_GPU\") is not None\n",
        "TPU = os.getenv(\"XRT_TPU_CONFIG\") is not None\n",
        "LOCAL = not KAGGLE and not COLAB\n",
        "\n",
        "if not LOCAL:\n",
        "    !git clone https://github.com/nclibz/MRKnee/\n",
        "\n",
        "if COLAB:\n",
        "    os.chdir('/content/MRKnee/')\n",
        "    !git checkout v3\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    DATADIR = \"/content/drive/MyDrive/MRKnee/data\"\n",
        "    if TPU:\n",
        "        !pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n",
        "\n",
        "if KAGGLE:\n",
        "    os.chdir('/kaggle/working/MRKnee/')\n",
        "    !git checkout v3\n",
        "    dataset_name = os.listdir('/kaggle/input')[0]\n",
        "    DATADIR = f\"/kaggle/input/{dataset_name}/\"\n",
        "    MODELDIR = DATADIR\n",
        "    \n",
        "    # INSTALL pyodbc driver\n",
        "    !sudo curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add -\n",
        "    !sudo curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list > /etc/apt/sources.list.d/mssql-release.list\n",
        "    !sudo apt-get update\n",
        "    !sudo ACCEPT_EULA=Y apt-get install -y msodbcsql18\n",
        "    \n",
        "    if TPU:\n",
        "        !pip install torchtext==0.9\n",
        "        !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "        !python pytorch-xla-env-setup.py --version 1.8\n",
        "\n",
        "if not LOCAL:\n",
        "    !pip install -U torchmetrics timm optuna albumentations scikit-image\n",
        "    %conda install -y pyodbc\n",
        "    BACKBONE = \"tf_efficientnetv2_s_in21k\"\n",
        "\n",
        "if LOCAL:\n",
        "    DATADIR = \"data\"\n",
        "    MODELDIR = \"src/\"\n",
        "    BACKBONE = 'tf_mobilenetv3_small_minimal_100'\n",
        "    %load_ext autoreload\n",
        "    %autoreload 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna\n",
        "import torch\n",
        "from optuna.pruners import ThresholdPruner\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "from src.augmentations import Augmentations\n",
        "from src.data import MRNet\n",
        "from src.metrics import AUC, Loss, MetricLogger\n",
        "from src.model import VanillaMRKnee\n",
        "from src.rdb import get_rdb_string\n",
        "from src.trainer import Trainer\n",
        "from src.utils import seed_everything\n",
        "\n",
        "seed_everything(123)\n",
        "rdb_string = get_rdb_string()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0odqVZ7KEwJj"
      },
      "outputs": [],
      "source": [
        "\n",
        "def objective(trial):\n",
        "    augs = Augmentations(\n",
        "        train_imgsize=(256, 256),\n",
        "        test_imgsize=(256, 256),\n",
        "        shift_limit=trial.suggest_int(\"shift_limit\", 0, 35, step = 5) / 100,\n",
        "        scale_limit=trial.suggest_int(\"scale_limit\", 0, 20, step = 5) / 100,\n",
        "        rotate_limit=trial.suggest_int(\"rotate_limit\", 0, 15, step = 5) / 100,\n",
        "        ssr_p=trial.suggest_int(\"ShiftScaleRotate_p\", 50, 80, step = 10) / 100,\n",
        "        clahe_p=trial.suggest_int(\"clahe_p\", 20, 70, step = 10) / 100,\n",
        "        trim_p=0.0,\n",
        "    )\n",
        "\n",
        "    train_ds = MRNet(\n",
        "        stage=\"train\",\n",
        "        diagnosis=\"meniscus\",\n",
        "        plane=PLANE,\n",
        "        clean=True,\n",
        "        transforms=augs,\n",
        "        datadir = DATADIR + \"MRNet\"\n",
        "    )\n",
        "\n",
        "    train_dl = DataLoader(\n",
        "            train_ds,\n",
        "            batch_size=1,\n",
        "            shuffle=True,\n",
        "            num_workers=2,\n",
        "            pin_memory=True,\n",
        "        )\n",
        "    \n",
        "    val_ds = MRNet(\n",
        "        stage=\"valid\",\n",
        "        diagnosis=\"meniscus\",\n",
        "        plane=PLANE,\n",
        "        clean=True,\n",
        "        transforms=augs,\n",
        "        datadir = DATADIR + \"MRNet\"\n",
        "    )\n",
        "\n",
        "    val_dl = DataLoader(\n",
        "            val_ds,\n",
        "            batch_size=1,\n",
        "            shuffle=False,\n",
        "            num_workers=2,\n",
        "            pin_memory=True,\n",
        "        )\n",
        "\n",
        "    model = VanillaMRKnee(\n",
        "        BACKBONE,\n",
        "        drop_rate=trial.suggest_int(\"drop_rate\", 50, 90, step=10) / 100,\n",
        "        )\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=trial.suggest_loguniform('lr', 1e-4, 1e-2),\n",
        "        weight_decay=trial.suggest_loguniform('adam_wd', 0.01, 0.1),\n",
        "        )\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                            \"min\",\n",
        "                                                            patience=4,\n",
        "                                                            )\n",
        "\n",
        "    metriclogger = MetricLogger(\n",
        "        train_metrics={\n",
        "            \"train_loss\": Loss(),\n",
        "            \"train_auc\": AUC(),\n",
        "        },\n",
        "        val_metrics={\n",
        "            \"val_loss\": Loss(),\n",
        "            \"val_auc\": AUC()\n",
        "        },\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(model, optimizer, scheduler, metriclogger)\n",
        "\n",
        "    for epoch in tqdm(range(20), desc='Epochs', disable=True):\n",
        "        trainer.train(train_dl)\n",
        "        trainer.test(val_dl)\n",
        "        \n",
        "        trial.report(metriclogger.val_loss.epoch_values[-1], epoch)\n",
        "\n",
        "        if trial.should_prune():\n",
        "            raise optuna.TrialPruned()\n",
        "\n",
        "    min_loss = torch.min(torch.Tensor(metriclogger.val_loss.epoch_values))\n",
        "        \n",
        "    return min_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "storage = optuna.storages.RDBStorage(\n",
        "            url=rdb_string,\n",
        "            heartbeat_interval=360,\n",
        "        )\n",
        "sampler = TPESampler(multivariate=True)\n",
        "\n",
        "study = optuna.create_study(\n",
        "    storage = storage,\n",
        "    study_name=f\"{PLANE}_{BACKBONE}\",\n",
        "    sampler = sampler,\n",
        "    pruner=ThresholdPruner(upper=1.5, n_warmup_steps=5, interval_steps=1),\n",
        "    load_if_exists=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## best params\n",
        "sag = {\n",
        "    \"shift_limit\": 25, \n",
        "    \"rotate_limit\": 10,\n",
        "    \"scale_limit\": 10, \n",
        "    \"ssr_p\": 80,\n",
        "    \"adam_wd\": 0.0539477, \n",
        "    \"lr\": 0.000220,\n",
        "    \"drop_rate\": 90,\n",
        "    \"clahe_p\": 20\n",
        "    }\n",
        "\n",
        "study.enqueue_trial(sag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "study.optimize(objective, n_trials=1) "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "colab.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "abca6c4c30ca8b1572eaf6dbdb066fe101b3df9342c8f2ea2bdb847c9dcb6eec"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('dl': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
