{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.7 64-bit ('dl': conda)"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python",
      "version": "3.9.7",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "20378a8ca53634062fe1d6aabe95744b9d01d18422d5e08ff305328b2ac520ac"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "import os\n",
        "\n",
        "KAGGLE =  os.getenv(\"KAGGLE_URL_BASE\") is not None\n",
        "COLAB = os.getenv(\"COLAB_GPU\") is not None\n",
        "TPU = os.getenv(\"XRT_TPU_CONFIG\") is not None\n",
        "LOCAL = not KAGGLE and not COLAB\n",
        "\n",
        "if not LOCAL:\n",
        "    !git clone https://github.com/nclibz/MRKnee/\n",
        "\n",
        "if COLAB:\n",
        "    os.chdir('/content/MRKnee/')\n",
        "    !git checkout v3\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    DATADIR = \"/content/drive/MyDrive/MRKnee/data\"\n",
        "    if TPU:\n",
        "        !pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n",
        "\n",
        "if KAGGLE:\n",
        "    os.chdir('/kaggle/working/MRKnee/')\n",
        "    !git checkout v3\n",
        "    DATADIR = \"/kaggle/input/mrknee/MRNet\"\n",
        "    \n",
        "    if TPU:\n",
        "        !pip install torchtext==0.9\n",
        "        !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "        !python pytorch-xla-env-setup.py --version 1.8\n",
        "\n",
        "if not LOCAL:\n",
        "    !pip install --quiet \"pytorch-lightning>=1.4.9\" \"torchmetrics>=0.5\" \"timm\" \"neptune-client\" \"optuna\" \"PyMySql\" \"torch-tb-profiler\"\n",
        "    !pip install albumentations --upgrade --quiet\n",
        "    BACKBONE = \"tf_efficientnetv2_s_in21k\"\n",
        "\n",
        "if LOCAL:\n",
        "    DATADIR = \"data\"\n",
        "    BACKBONE = \"tf_mobilenetv3_small_minimal_100\"\n",
        "    %load_ext autoreload\n",
        "    %autoreload 2"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "DIAGNOSIS = \"acl\"\n",
        "PLANE = \"sagittal\""
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "from src.model import MRKnee\n",
        "from src.data import MRKneeDataModule\n",
        "from src.augmentations import Augmentations\n",
        "from src.callbacks import Callbacks\n",
        "from src.cfg import Cfg\n",
        "import pytorch_lightning as pl\n",
        "import optuna\n",
        "\n",
        "pl.seed_everything(123)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 123\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "123"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "metadata": {
        "id": "mS6KbHiLEwJi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "\n",
        "def objective(trial, diagnosis=DIAGNOSIS, plane=PLANE, backbone=BACKBONE, datadir=DATADIR, profile = False):\n",
        "\n",
        "    model = MRKnee(\n",
        "        backbone=backbone,\n",
        "        drop_rate=0.0,\n",
        "        final_drop=0.0,\n",
        "        learning_rate=0.0001,\n",
        "        log_auc=True,\n",
        "        log_ind_loss=False,\n",
        "        adam_wd=0.01,\n",
        "        max_epochs=20,\n",
        "        precision=32,\n",
        "    )\n",
        "\n",
        "    augs = Augmentations(\n",
        "        model,\n",
        "        shift_limit=0.20,\n",
        "        scale_limit=0.20,\n",
        "        rotate_limit=30,\n",
        "        reverse_p=0.5,\n",
        "        same_range=True,\n",
        "        indp_normalz=True,\n",
        "    )\n",
        "\n",
        "    dm = MRKneeDataModule(\n",
        "        datadir=datadir,\n",
        "        diagnosis=diagnosis,\n",
        "        plane=plane,\n",
        "        transforms=augs,\n",
        "        clean=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        trim_train=True,\n",
        "    )\n",
        "\n",
        "    configs = Cfg(model = model, dm = dm, augs = augs)\n",
        "    cfg = configs.get_cfg()\n",
        "    \n",
        "    if trial is not None:\n",
        "        callbacks = Callbacks(cfg, trial, neptune_name=\"tester\")\n",
        "        neptune_logger = callbacks.get_neptune_logger()\n",
        "        list_of_cbs = callbacks.get_callbacks()\n",
        "        fast_dev_run = False\n",
        "    else:\n",
        "        neptune_logger = False\n",
        "        list_of_cbs = None\n",
        "        fast_dev_run = 50\n",
        "\n",
        "    profiler = pl.profiler.PyTorchProfiler(dirpath = \"src/logs\", filename = \"profiler\") if profile else False\n",
        "        \n",
        "\n",
        "\n",
        "    trainer = pl.Trainer(\n",
        "        gpus=1,\n",
        "        precision=cfg[\"precision\"],\n",
        "        max_epochs=cfg[\"max_epochs\"],\n",
        "        logger=neptune_logger,\n",
        "        log_every_n_steps=100,\n",
        "        num_sanity_val_steps=0,\n",
        "        callbacks=list_of_cbs,\n",
        "        progress_bar_refresh_rate=20,\n",
        "        deterministic=True,\n",
        "        profiler = profiler, \n",
        "        fast_dev_run = fast_dev_run,\n",
        "    )\n",
        "\n",
        "    trainer.fit(model, dm)\n",
        "\n",
        "    ## UPLOAD BEST CHECKPOINTS TO LOG\n",
        "    if trial is not None:\n",
        "        callbacks.upload_best_checkpoints()\n",
        "\n",
        "    return callbacks.model_checkpoint.best_model_score.item()\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "0odqVZ7KEwJj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "# For testing\n",
        "#objective(trial = None)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "\n",
        "pruner = optuna.pruners.HyperbandPruner(min_resource=10)\n",
        "sampler = optuna.samplers.TPESampler(multivariate=True)\n",
        "storage = optuna.storages.RDBStorage(\n",
        "    url=\"mysql+pymysql://admin:Testuser1234@database-1.c17p2riuxscm.us-east-2.rds.amazonaws.com/optuna\",\n",
        "    heartbeat_interval=120,\n",
        "    grace_period=360,\n",
        ")\n",
        "study_name = f\"{DIAGNOSIS}_{PLANE}_{BACKBONE}\"\n",
        "\n",
        "study = optuna.create_study(\n",
        "    storage=storage,\n",
        "    study_name=study_name,\n",
        "    load_if_exists=True,\n",
        "    sampler=sampler,\n",
        "    pruner=pruner,\n",
        "    direction=\"minimize\",\n",
        ")\n",
        "#study.enqueue_trial({\n",
        "#    'dropout': 55,\n",
        "#    'lr': 3.e-4,\n",
        "#    'rotate': 25,\n",
        "#    'scale': 8,\n",
        "#    'shift': 10,\n",
        "#    'adam_wd': 0.0900\n",
        "#    })\n",
        "\n",
        "\n",
        "study.optimize(objective, n_trials=40, timeout=8 * 60 * 60)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/nicolai/miniconda3/envs/dl/lib/python3.9/site-packages/optuna/samplers/_tpe/sampler.py:263: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2021-10-07 14:50:54,257]\u001b[0m Using an existing study with name 'acl_sagittal_tf_mobilenetv3_small_minimal_100' instead of creating a new one.\u001b[0m\n",
            "NeptuneLogger will work in online mode\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name       | Type        | Params\n",
            "-------------------------------------------\n",
            "0 | backbone   | MobileNetV3 | 1.0 M \n",
            "1 | final_drop | Dropout     | 0     \n",
            "2 | clf        | Linear      | 1.0 K \n",
            "-------------------------------------------\n",
            "1.0 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.0 M     Total params\n",
            "4.082     Total estimated model params size (MB)\n",
            "/home/nicolai/miniconda3/envs/dl/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "/home/nicolai/miniconda3/envs/dl/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training: -1it [00:00, ?it/s]https://ui.neptune.ai/nclibz/tester/e/TES-6\n",
            "Epoch 0:  92%|█████████▏| 1140/1241 [01:16<00:06, 14.98it/s, loss=1.01, v_num=ES-6]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: 100%|██████████| 1241/1241 [01:21<00:00, 15.22it/s, loss=1.17, v_num=ES-6, val_loss=0.727, val_auc=0.727]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0, global step 1120: val_loss reached 0.72745 (best 0.72745), saving model to \"/home/nicolai/OneDrive/Forskning/Projekter/MRKnee/checkpoints/trial3/epoch=00-val_loss=0.73-val_auc=0.73.ckpt\" as top 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:   0%|          | 0/1241 [00:00<00:01, 1083.80it/s, loss=1.17, v_num=ES-6, val_loss=0.727, val_auc=0.727] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:  92%|█████████▏| 1140/1241 [01:10<00:06, 16.08it/s, loss=0.671, v_num=ES-6, val_loss=0.727, val_auc=0.727, train_loss=1.180]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: 100%|██████████| 1241/1241 [01:15<00:00, 16.36it/s, loss=0.582, v_num=ES-6, val_loss=0.647, val_auc=0.788, train_loss=1.180]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1, global step 2241: val_loss reached 0.64667 (best 0.64667), saving model to \"/home/nicolai/OneDrive/Forskning/Projekter/MRKnee/checkpoints/trial3/epoch=01-val_loss=0.65-val_auc=0.79.ckpt\" as top 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2:   0%|          | 0/1241 [00:00<00:00, 1373.38it/s, loss=0.582, v_num=ES-6, val_loss=0.647, val_auc=0.788, train_loss=1.180] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2:  92%|█████████▏| 1140/1241 [01:15<00:06, 15.03it/s, loss=0.485, v_num=ES-6, val_loss=0.647, val_auc=0.788, train_loss=0.778]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: 100%|██████████| 1241/1241 [01:21<00:00, 15.31it/s, loss=0.517, v_num=ES-6, val_loss=0.674, val_auc=0.817, train_loss=0.778]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2, global step 3362: val_loss reached 0.67356 (best 0.64667), saving model to \"/home/nicolai/OneDrive/Forskning/Projekter/MRKnee/checkpoints/trial3/epoch=02-val_loss=0.67-val_auc=0.82.ckpt\" as top 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3:   0%|          | 0/1241 [00:00<00:05, 238.27it/s, loss=0.517, v_num=ES-6, val_loss=0.674, val_auc=0.817, train_loss=0.778] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3:  92%|█████████▏| 1140/1241 [01:16<00:06, 14.86it/s, loss=0.364, v_num=ES-6, val_loss=0.674, val_auc=0.817, train_loss=0.490]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: 100%|██████████| 1241/1241 [01:22<00:00, 15.08it/s, loss=0.419, v_num=ES-6, val_loss=0.858, val_auc=0.668, train_loss=0.490]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3, global step 4483: val_loss was not in top 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4:   0%|          | 0/1241 [00:00<00:02, 424.70it/s, loss=0.419, v_num=ES-6, val_loss=0.858, val_auc=0.668, train_loss=0.490] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4:  92%|█████████▏| 1140/1241 [01:19<00:07, 14.30it/s, loss=0.0698, v_num=ES-6, val_loss=0.858, val_auc=0.668, train_loss=0.257]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: 100%|██████████| 1241/1241 [01:25<00:00, 14.46it/s, loss=0.0688, v_num=ES-6, val_loss=1.150, val_auc=0.725, train_loss=0.257]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4, global step 5604: val_loss was not in top 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5:   0%|          | 0/1241 [00:00<00:02, 525.93it/s, loss=0.0688, v_num=ES-6, val_loss=1.150, val_auc=0.725, train_loss=0.257] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5:  92%|█████████▏| 1140/1241 [01:14<00:06, 15.42it/s, loss=0.0224, v_num=ES-6, val_loss=1.150, val_auc=0.725, train_loss=0.0965]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: 100%|██████████| 1241/1241 [01:19<00:00, 15.67it/s, loss=0.0227, v_num=ES-6, val_loss=0.764, val_auc=0.809, train_loss=0.0965]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5, global step 6725: val_loss was not in top 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6:   0%|          | 0/1241 [00:00<00:03, 340.01it/s, loss=0.0227, v_num=ES-6, val_loss=0.764, val_auc=0.809, train_loss=0.0965] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6:  92%|█████████▏| 1140/1241 [01:18<00:06, 14.58it/s, loss=0.00837, v_num=ES-6, val_loss=0.764, val_auc=0.809, train_loss=0.0266]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: 100%|██████████| 1241/1241 [01:23<00:00, 14.86it/s, loss=0.00837, v_num=ES-6, val_loss=1.060, val_auc=0.808, train_loss=0.0266]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6, global step 7846: val_loss was not in top 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7:   0%|          | 0/1241 [00:00<00:00, 1351.26it/s, loss=0.00837, v_num=ES-6, val_loss=1.060, val_auc=0.808, train_loss=0.0266] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7:  92%|█████████▏| 1140/1241 [01:16<00:06, 14.83it/s, loss=0.00155, v_num=ES-6, val_loss=1.060, val_auc=0.808, train_loss=0.00803]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: 100%|██████████| 1241/1241 [01:22<00:00, 15.11it/s, loss=0.00156, v_num=ES-6, val_loss=1.010, val_auc=0.836, train_loss=0.00803]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7, global step 8967: val_loss was not in top 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8:   0%|          | 0/1241 [00:00<00:02, 512.44it/s, loss=0.00156, v_num=ES-6, val_loss=1.010, val_auc=0.836, train_loss=0.00803] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8:  92%|█████████▏| 1140/1241 [01:15<00:06, 15.03it/s, loss=0.000838, v_num=ES-6, val_loss=1.010, val_auc=0.836, train_loss=0.00306]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: 100%|██████████| 1241/1241 [01:21<00:00, 15.31it/s, loss=0.000838, v_num=ES-6, val_loss=0.919, val_auc=0.836, train_loss=0.00306]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8, global step 10088: val_loss was not in top 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9:   0%|          | 0/1241 [00:00<00:03, 316.15it/s, loss=0.000838, v_num=ES-6, val_loss=0.919, val_auc=0.836, train_loss=0.00306] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9:  73%|███████▎  | 900/1241 [01:02<00:23, 14.34it/s, loss=0.00126, v_num=ES-6, val_loss=0.919, val_auc=0.836, train_loss=0.00128] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/nicolai/miniconda3/envs/dl/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1051: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9:  73%|███████▎  | 900/1241 [01:13<00:27, 12.32it/s, loss=0.00126, v_num=ES-6, val_loss=0.919, val_auc=0.836, train_loss=0.00128]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-07 15:04:39,402]\u001b[0m Trial 3 finished with value: 0.6466671228408813 and parameters: {}. Best is trial 3 with value: 0.646667.\u001b[0m\n",
            "NeptuneLogger will work in online mode\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name       | Type        | Params\n",
            "-------------------------------------------\n",
            "0 | backbone   | MobileNetV3 | 1.0 M \n",
            "1 | final_drop | Dropout     | 0     \n",
            "2 | clf        | Linear      | 1.0 K \n",
            "-------------------------------------------\n",
            "1.0 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.0 M     Total params\n",
            "4.082     Total estimated model params size (MB)\n",
            "/home/nicolai/miniconda3/envs/dl/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "/home/nicolai/miniconda3/envs/dl/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9:  73%|███████▎  | 900/1241 [01:23<00:31, 10.77it/s, loss=0.00126, v_num=ES-6, val_loss=0.919, val_auc=0.836, train_loss=0.00128]\n",
            "https://ui.neptune.ai/nclibz/tester/e/TES-7\n",
            "Epoch 0:   0%|          | 0/1241 [00:00<00:03, 392.47it/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:  60%|█████▉    | 740/1241 [00:50<00:33, 14.79it/s, loss=1.21, v_num=ES-7] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/nicolai/miniconda3/envs/dl/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1051: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
            "\u001b[33m[W 2021-10-07 15:05:40,106]\u001b[0m Trial 4 failed because of the following error: AttributeError(\"'NoneType' object has no attribute 'tolist'\")\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/nicolai/miniconda3/envs/dl/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"/tmp/ipykernel_9268/379676973.py\", line 71, in objective\n",
            "    callbacks.upload_best_checkpoints()\n",
            "  File \"/home/nicolai/OneDrive/Forskning/Projekter/MRKnee/src/callbacks.py\", line 63, in upload_best_checkpoints\n",
            "    \"best_val_loss\", self.model_checkpoint.best_model_score.tolist()\n",
            "AttributeError: 'NoneType' object has no attribute 'tolist'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'tolist'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_9268/493141133.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m60\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_9268/379676973.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial, diagnosis, plane, backbone, datadir, profile)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;31m## UPLOAD BEST CHECKPOINTS TO LOG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload_best_checkpoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_model_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/OneDrive/Forskning/Projekter/MRKnee/src/callbacks.py\u001b[0m in \u001b[0;36mupload_best_checkpoints\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupload_best_checkpoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         self.neptune_logger.experiment.set_property(\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;34m\"best_val_loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_model_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         )\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'tolist'"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:  60%|█████▉    | 740/1241 [01:07<00:45, 11.03it/s, loss=1.21, v_num=ES-7]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Info (NVML): The operating system has blocked the request.. GPU usage metrics may not be reported. For more information, see https://docs-legacy.neptune.ai/logging-and-managing-experiment-results/logging-experiment-data.html#hardware-consumption \n",
            "Info (NVML): The operating system has blocked the request.. GPU usage metrics may not be reported. For more information, see https://docs-legacy.neptune.ai/logging-and-managing-experiment-results/logging-experiment-data.html#hardware-consumption \n"
          ]
        }
      ],
      "metadata": {
        "id": "JdYUoCTxEwJk"
      }
    }
  ]
}