{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "CFG = {\n",
        "    \"dataset\": \"mrnet\",\n",
        "    \"plane\": \"coronal\",\n",
        "    \"protocol\": \"TSE\",\n",
        "    \"backbone\": \"tf_efficientnetv2_s_in21k\", #\"tf_efficientnetv2_s_in21k\" or \"tf_mobilenetv3_small_minimal_100\"\n",
        "    \"n_epochs\": 15,\n",
        "    \"n_trials\": 1,\n",
        "    \"wandb_project\": \"mrknee\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "\n",
        "!git clone https://github.com/nclibz/MRKnee/\n",
        "os.chdir('/kaggle/working/MRKnee/')\n",
        "!git checkout v3\n",
        "dataset_name = os.listdir('/kaggle/input')[0]\n",
        "DATADIR = f\"/kaggle/input/{dataset_name}/\"\n",
        "\n",
        "# INSTALL pyodbc driver\n",
        "!sudo curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add -\n",
        "!sudo curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list > /etc/apt/sources.list.d/mssql-release.list\n",
        "!sudo apt-get update\n",
        "!sudo ACCEPT_EULA=Y apt-get install -y msodbcsql18\n",
        "# Packages\n",
        "!pip install -U torchmetrics timm optuna albumentations scikit-image madgrad wandb\n",
        "%conda install -y pyodbc\n",
        "\n",
        "from kaggle_secrets import UserSecretsClient\n",
        "user_secrets = UserSecretsClient()\n",
        "ENV = {}\n",
        "ENV[\"RDB_URL\"] = user_secrets.get_secret(\"RDB_URL\")\n",
        "ENV['WANDB_API_KEY'] = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
        "\n",
        "## DIRTY FIX FOR OAI IMGDIR\n",
        "\n",
        "if CFG['dataset'] == 'oai':\n",
        "    IMGDIR = \"imgs/imgs\"\n",
        "else:\n",
        "    IMGDIR = \"imgs\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import wandb\n",
        "from madgrad import MADGRAD\n",
        "import optuna\n",
        "from src.augmentations import Augmentations\n",
        "from src.data import OAI, MRNet, get_dataloader\n",
        "from src.metrics import AUC, Loss, MetricLogger\n",
        "from src.model import VanillaMRKnee\n",
        "from src.model_checkpoint import SaveModelCheckpoint\n",
        "from src.trainer import Trainer\n",
        "from src.utils import seed_everything\n",
        "\n",
        "seed_everything(123)\n",
        "\n",
        "wandb.login(key=ENV[\"WANDB_API_KEY\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0odqVZ7KEwJj"
      },
      "outputs": [],
      "source": [
        "\n",
        "def objective(trial, CFG = CFG):\n",
        "    \n",
        "    augs = Augmentations(\n",
        "        ssr_p=trial.suggest_int('ssr_p', 30, 80, 5) / 100,\n",
        "        shift_limit=trial.suggest_int('shift_limit', 0, 30, 5) / 100,\n",
        "        scale_limit=trial.suggest_int('scale_limit', 0, 30,5) / 100,\n",
        "        rotate_limit=trial.suggest_int('rotate_limit', 0, 30,5) / 100,\n",
        "        bc_p=0.00,\n",
        "        brigthness_limit=0.10,\n",
        "        contrast_limit=0.10,\n",
        "        re_p=trial.suggest_int('re_p', 0, 80, 10) / 100,\n",
        "        clahe_p=trial.suggest_int('clahe_p', 0, 80, 10) / 100,\n",
        "        trim_p=0.0,\n",
        "    )\n",
        "\n",
        "    if CFG[\"dataset\"] == \"oai\":\n",
        "        DATAREADER = OAI\n",
        "    elif CFG[\"dataset\"] == \"mrnet\":\n",
        "        DATAREADER = MRNet\n",
        "\n",
        "    # TODO: flytte dr loading ind i get_dataloader\n",
        "\n",
        "    train_dr = DATAREADER(\n",
        "        stage=\"train\",\n",
        "        diagnosis=\"meniscus\",\n",
        "        plane=CFG[\"plane\"],\n",
        "        protocol=CFG[\"protocol\"],\n",
        "        clean=True,\n",
        "        datadir = DATADIR,\n",
        "        img_dir = IMGDIR\n",
        "    )\n",
        "\n",
        "    val_dr = DATAREADER(\n",
        "        stage=\"valid\",\n",
        "        diagnosis=\"meniscus\",\n",
        "        plane=CFG[\"plane\"],\n",
        "        protocol=CFG[\"protocol\"],\n",
        "        clean=False,\n",
        "        datadir = DATADIR,\n",
        "        img_dir = IMGDIR\n",
        "\n",
        "    )\n",
        "\n",
        "    train_dl = get_dataloader(train_dr, augs)\n",
        "    val_dl = get_dataloader(val_dr, augs)\n",
        "\n",
        "    model = VanillaMRKnee(CFG[\"backbone\"], pretrained=True, drop_rate=trial.suggest_int('drop_rate', 40, 90, 5) / 100)\n",
        "\n",
        "### OPTIMIZERS\n",
        "\n",
        "    LR = trial.suggest_loguniform('lr', 1e-5, 1e-3)\n",
        "    WD = trial.suggest_loguniform('weigth_decay', 1e-5, 1e-2)\n",
        "    OPTIM_NAME = trial.suggest_categorical(\"optimizer\", [\"madgrad\", \"adamw\"])\n",
        "\n",
        "    if OPTIM_NAME == \"madgrad\":\n",
        "        optimizer = MADGRAD(model.parameters(),lr=LR, weight_decay=WD)\n",
        "    elif OPTIM_NAME == \"adamw\":\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr= LR, weight_decay=WD)\n",
        "\n",
        "### SCHEDULER\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        \"min\",\n",
        "        patience=4,\n",
        "    )\n",
        "\n",
        "## HELPER CLASSES\n",
        "    metriclogger = MetricLogger(\n",
        "        train_metrics={\"train_loss\": Loss(), \"train_auc\": AUC()},\n",
        "        val_metrics={\"val_loss\": Loss(), \"val_auc\": AUC()},\n",
        "    )\n",
        "\n",
        "    chpkt = SaveModelCheckpoint(\"checkpoint\")\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model,\n",
        "        optimizer,\n",
        "        scheduler,\n",
        "        metriclogger,\n",
        "        label_smoothing=trial.suggest_int('lbl_smoothing', 0, 10, 5) / 100,\n",
        "        progressbar=True,\n",
        "    )\n",
        "\n",
        "### LOGGING\n",
        "\n",
        "    CFG = {**CFG, **trial.params}\n",
        "    wandb.init(project=CFG['wandb_project'], entity=\"nclibz\", config=CFG)\n",
        "\n",
        "### TRAINING\n",
        "\n",
        "    for epoch in range(CFG[\"n_epochs\"]):\n",
        "        trainer.train(train_dl)\n",
        "        trainer.validate(val_dl)\n",
        "\n",
        "        metrics = {k: metriclogger.get_metric(k, epoch) for k in metriclogger.all_metrics}\n",
        "\n",
        "        wandb.log(metrics)\n",
        "\n",
        "        is_best = chpkt.check(metrics[\"val_loss\"], model, optimizer, scheduler, epoch)\n",
        "        if is_best:\n",
        "            wandb.save(chpkt.get_checkpoint_path())\n",
        "\n",
        "        # TODO: Flytte print af metrics ind i metriclogger?\n",
        "        print(\n",
        "            f\"EPOCH: {epoch} / {CFG['n_epochs']} \\n train_loss: {metrics['train_loss']:.3f} val_loss: {metrics['val_loss']:.3f} \\n train_auc: {metrics['train_auc']:.3f} val_auc: {metrics['val_auc']:.3f} \"\n",
        "        )\n",
        "\n",
        "\n",
        "    wandb.finish()\n",
        "               \n",
        "    return metriclogger.get_min(\"val_loss\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "storage = optuna.storages.RDBStorage(\n",
        "            url=ENV['RDB_URL'],\n",
        "            heartbeat_interval=360,\n",
        "        )\n",
        "sampler = optuna.samplers.TPESampler(multivariate=True)\n",
        "\n",
        "study = optuna.create_study(\n",
        "    storage = storage,\n",
        "    study_name=f\"{CFG['dataset']}_{CFG['plane']}_{CFG['backbone']}\",\n",
        "    sampler = sampler,\n",
        "    load_if_exists=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "study.optimize(objective, n_trials=CFG['n_trials']) "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "colab.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "93d61b45e3b9b9f738b356a5e77fb59e313fea1003bb46cfc1eb5d8a1d2bde49"
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('dl')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
