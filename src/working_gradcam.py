# -*- coding: utf-8 -*-
"""gradcam.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-jk55Hq0AdBiaJE3rYevCuog9uZ5UdrN
"""

from google.colab import drive
drive.mount('/content/drive')

!git clone https://github.com/nclibz/MRKnee/
import os
os.chdir('/content/MRKnee/')
!git checkout lstm

!pip install pytorch-lightning
!pip install timm
#!pip install trulens
import albumentations as A
import numpy as np
import pandas as pd
import torch
import matplotlib.pyplot as plt

from src.model import MRKnee

# INSTANTIATE MODEL

backbone = "efficientnet_b1"
plane = "sagittal"
diag = "acl"
ckpt = '/content/drive/MyDrive/MRNet/models/' + diag + "_" + plane + ".ckpt"
img_sz = 240
device = "cuda"

model = MRKnee.load_from_checkpoint(ckpt, planes=[plane], backbone=backbone).to(device = device).eval()

# INPUT
paths = []
for root, dirs, files in os.walk(os.path.abspath("/content/drive/MyDrive/MRNet/valid")):
    for file in files:
        if plane in root:
            paths.append(os.path.join(root, file))

acl_labels = pd.read_csv("/content/drive/MyDrive/MRNet/valid-acl.csv", header = None)

pos_lbls = acl_labels[acl_labels[1] == 1][0].values.tolist()

lbl = str(pos_lbls[2])

path = [path for path in paths if lbl in path]

path = path[-1]

def do_aug(imgs, transf):
    img_dict = {}
    target_dict = {}
    for i in range(imgs.shape[0]):
        if i == 0:
            img_dict["image"] = imgs[i, :, :]
        else:
            img_name = "image" + f"{i}"
            img_dict[img_name] = imgs[i, :, :]
            target_dict[img_name] = "image"
    transf = A.Compose(transf)
    transf.add_targets(target_dict)
    out = transf(**img_dict)
    out = list(out.values())
    return out  # returns list of np arrays

imgs = np.load(path)
imgs = do_aug(imgs, transf=[A.CenterCrop(img_sz, img_sz)])
imgs = torch.as_tensor(imgs, dtype=torch.float32)
imgs = (imgs - imgs.min()) / (imgs.max() - imgs.min()) * 255
if plane == "axial":
    MEAN, SD = 66.4869, 60.8146
elif plane == "sagittal":
    MEAN, SD = 60.0440, 48.3106
elif plane == "coronal":
    MEAN, SD = 61.9277, 64.2818
imgs = (imgs - MEAN) / SD
imgs = imgs.unsqueeze(1)  # create channel dim
imgs = imgs.unsqueeze(0)  # create channel dim
imgs = imgs.to(device=device)
imgs.shape

# get activation of last conv layer
activation = {}
def getActivation(name):
    # the hook signature
    def hook(model, input, output):
        activation[name] = output
    return hook

h1 = model.backbones[-1][10].register_forward_hook(getActivation('2dconv'))

res = model(imgs)

acts = activation["2dconv"]
acts.shape

# get gradients
grads = []

def grad_hook(grad):
  grads.append(grad)

acts.register_hook(grad_hook)
res.backward()
grad = grads[0]
grad.shape

## select specific image 
img_no = 15  
img_grad = grad[img_no,:,:,:].unsqueeze(0).detach().cpu()
img_act = acts[img_no,:,:,:].unsqueeze(0).detach().cpu()

img_act.shape, img_grad.shape

#https://medium.com/the-owl/gradcam-in-pytorch-7b700caa79e5

pooled_grads = torch.mean(img_grad, dim=[0,2,3]).detach().cpu()

for i in range(img_act.shape[1]):
  img_act[:,i,:,:] *= pooled_grads[i]

pooled_grads.shape, img_act.shape

from torchvision.transforms import Resize
import torch.nn.functional as F
heatmap = torch.mean(img_act, dim=1).squeeze()
heatmap = F.relu(heatmap)

# normalize the heatmap
heatmap /= torch.max(heatmap)

# draw the heatmap
#plt.matshow(heatmap.squeeze())

from torchvision.transforms import Resize

imgs = np.load(path)

img = imgs[img_no, :, :]
img =torch.as_tensor(img, dtype = torch.float32).unsqueeze(0)

# resize heatmap
heatmap= heatmap.unsqueeze(0)
resize = Resize(size = (img.shape[1]))
heatmap = resize(heatmap)
heatmap = 255 * heatmap

heatmap.shape, torch.max(heatmap), img.shape, torch.max(img)

plt.matshow(heatmap.squeeze(0))
heatmap.shape, img.shape

fig, axs = plt.subplots(1)
axs.imshow(img.squeeze(0), cmap = "gray")
axs.imshow(heatmap.squeeze(0), cmap = "jet", alpha = 0.4)
axs.axis('off')
fig.savefig("filename.svg", dpi = 300, bbox_inches ="tight")